---
title: "LAB 1.2 ML"
author: "DataLab CSIC"
date: "2/2/2023"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introducción

En este lab hacemos una intro a ML.  Recordamos regresión lineal y el problema de sobreajuste. Después se discute el problema de selección de modelos en knns y concluimos con una breve ilustración de regresión logística.  Revisamos como ejemplo de aprendizaje no supervisado algunas cuestiones sobre ACPs, primero una ilustración básica y luego dos ilustraciones a proyección y compresión. Finalmente, se hace un recordatorios
de conceptos de optimización en R y validación. 

En esta segunda parte introducimos varias ideas sobre clasificación, selección de modelos, entrenamiento y test,… Adaptamos algunos ejemplos de libro  ESL.

## kNNs

En esta parte hacemos un recordatorio de Knns y alguna otras ideas fundamentales en ML. Cargamos primero la librería class que tiene bastantes cosas de clasificación.
Busca package class R para más info. Vamos a emplear los datos iris, así que vemos algunas cosas de ellos.
```{r ,eval=FALSE}
library(class) 
plot(iris)       
summary(iris)    
str(iris)
head(iris)
n <- nrow(iris)
n
```
Nuestro objetivo es intentar predecir la quinta variable (el tipo de iris) en función de las otras cuatro variables. Usaremos un algoritmo knn. Partiremos el conjunto de datos usando 75% de datos para entrenamiento y el resto para test. Haz primero
help(sample)!!!
```{r ,eval=FALSE}
idx <- sample(n, n*0.75)
train <- iris[idx, ]
test <- iris[-idx, ]
train
test
```
Separamos ahora la variable de respuesta (la quinta) de las variables explicativas en el conjunto de entrenamiento y en el de test. Observa en el panel de RStudio como describe la variable y 
```{r ,eval=FALSE}
y_train <- train[,  5]
X_train <- train[, -5]
y_test <- test[,  5]
X_test <- test[, -5]
```
Ajustamos ahora un modelo knn con k=3. Con ayuda de help(knn) entendemos la sintaxis de knn y el algoritmo empleado. Después ejecutamos y vemos la tasa de acierto. 
```{r ,eval=FALSE}
y_pred <- knn(X_train, X_test, y_train, k=3)
y_pred
mean(y_test == y_pred)*100
```
Los resultados parecen buenos.  Lógicamente el anterior se refiere a una sola partición test-train. Aquí exploramos 10 réplicas del proceso
```{r ,eval=FALSE}
xx<-matrix(0,1,10)
yy<-matrix(0,1,10)
    for (i in 1:10)
    { idx <- sample(n, n*0.75)
train <- iris[idx, ]
test <- iris[-idx, ]
y_train <- train[,  5]
X_train <- train[, -5]
y_test <- test[,  5]
X_test <- test[, -5]
# Corregida errata antes habia puesto k=i, las prisas son malas...
y_pred <- knn(X_train, X_test, y_train, k=3)
yy[i]<-mean(y_test == y_pred)*100
xx[i]<-i
}
  plot(xx[1,],yy[1,])   
mean(yy[1,])
sd(yy[1,])
```
Aquí k es un parámetro a fijar y debemos elegirlo. Mostramos los resultados desde k=1 hasta 10. Esto solo explica/ilustra el problema vemos cross-validation en otro lab
```{r ,eval=FALSE}
yy<-matrix(0,1,10)
    for (i in 2:10)
    { 
     idx <- sample(n, n*0.6)
train <- iris[idx, ]
test <- iris[-idx, ]
y_train <- train[,  5]
X_train <- train[, -5]
y_test <- test[,  5]
X_test <- test[, -5] 
y_pred <- knn(X_train, X_test, y_train, k=i)
yy[i]<-mean(y_test == y_pred)*100
}
 plot(yy[1,2:10])   
```    
## Regresión logística 
Aquí hacemos un breve recordatorio de regresión logística con glm empleando el conjunto de datos Smarket (Stock Market) de ISLR. Lo exploramos un poco primero una vez cargado el paquete ISLR.
```{r ,eval=FALSE}
library(ISLR)
help(Smarket)
names(Smarket)
dim(Smarket)
head(Smarket)
summary(Smarket)
pairs(Smarket)
```
Usamos la función cor para calcular las correlaciones. Ojo a lo que pasa en el primer intento (falla...)
```{r ,eval=FALSE}
cor(Smarket)
cor(Smarket[,-9])
```
La única correlación sustancial parece entre Year y Volume. Dibujamos Volume y comentamos 
```{r ,eval=FALSE}
attach(Smarket)
plot(Volume)
```
Ahora hacemos  un modelo de regresión logística con glm intentando relacionar Direction (si sube  o baja) con lag1 hasta lag 5 y Volume. Hacemos antes help(glm) para entender la sintaxis. Ajustamos y desplegamos el modelo para discutirlo. Recordamos algunas cuestiones sobre el modelo (interpretación de signos, de coeficientes,….)
```{r ,eval=FALSE}
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial)
summary(glm.fit)
coef(glm.fit)
summary(glm.fit)$coef
summary(glm.fit)$coef[,4]
```
Ahora hacemos  predicciones (como probabilidades de que suba), desplegamos 10 de ellas y recordamos con contrasts lo que ha hecho R
```{r ,eval=FALSE}
glm.probs=predict(glm.fit,type="response")
glm.probs[1:10]
contrasts(Direction)
```
Ahora creamos un vector con las predicciones. Si la probabilidad es mayor que  0.5, sube
```{r ,eval=FALSE}
glm.pred=rep("Down",1250)
glm.pred[glm.probs>.5]="Up"
```
Construimos ahora la matriz de confusión y evaluamos la exactitud
(accuracy) del modelo (Piensa en las otras medidas que comentamos en clase, luego 
usamos la precisión).
```{r ,eval=FALSE}
table(glm.pred,Direction)
(507+145)/1250
mean(glm.pred==Direction)
```
Los resultados no parecen muy buenos. Sólo algo mejores que prediciendo al azar.
Además hemos usado todos los datos para el entrenamiento. Intentamos mejorar la evaluación entrenando con los datos anteriores a 2005 y usando los de 2005 para test
```{r ,eval=FALSE}
train=(Year<2005)
Smarket.2005=Smarket[!train,]
dim(Smarket.2005)
Direction.2005=Direction[!train]
```
Ajustamos ahora el modelo con esa partición de los datos.
```{r ,eval=FALSE}
glm.fit=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial,subset=train)
glm.probs=predict(glm.fit,Smarket.2005,type="response")
```
Hacemos ahora la evaluación. 
```{r ,eval=FALSE}
glm.pred=rep("Down",252)
glm.pred[glm.probs>.5]="Up"
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
mean(glm.pred!=Direction.2005)
```
Pero el modelo sigue sin ser bueno (fijate que la tasa de acierto y la tasa de fallo
que acabamos de calcular sugieren que es peor que predecir aleatoriamente!!!).  Quitamos algunas variables que no parecen ayudar mucho ajustando un nuevo modelo.
```{r ,eval=FALSE}
glm.fit=glm(Direction~Lag1+Lag2,data=Smarket,family=binomial,subset=train)
glm.probs=predict(glm.fit,Smarket.2005,type="response")
glm.pred=rep("Down",252)
glm.pred[glm.probs>.5]="Up"
table(glm.pred,Direction.2005)
mean(glm.pred==Direction.2005)
106/(106+76)
```
El modelo parece algo mejor, siendo más sencillo. Además, el último valor
calculado (la precisión 106/(106+76)) sugiere que lo hacemos algo mejor
al predecir subidas, por lo que una regla de decisión podría ser...  Para concluir hacemos predicciones para unos valores particulares de los predictores, empleando la función predict
```{r ,eval=FALSE}
predict(glm.fit,newdata=data.frame(Lag1=c(1.2,1.5),Lag2=c(1.1,-0.8)),type="response")
```
Qué decisiones tendríamos que tomar en estos dos casos?
