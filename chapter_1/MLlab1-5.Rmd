---
title: "LAB 1.5 ML"
author: "DataLAb CSIC"
date: "2/2/2023"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introducción

En este lab hacemos una intro a ML.  Recordamos regresión líneal y el problema de sobreajuste. Después se discute el problema de selección de modelos en knns y concluimos con una breve ilustración de regresión logística.  Revisamos como ejemplo de aprendizaje no supervisado algunas cuestiones sobre ACPs, primero una ilustración básica y luego dos ilustraciones a proyección y compresión. Finalmente, se hace un
revisión de optimización y validación en R.

En esta ultima parte hacemos una introduccion a validación. Adaptamos un par 
de ejemplos de ILSR.

## Datos que usamos. Un poco de info

Empleamos el conjunto de datos Auto. Sacamos primeras intuiciones sobre 
los datos. Cargamos ISLR.
 
```{r ,eval=FALSE}
library(ISLR)
fix(Auto)
dim(Auto)
head(Auto) 
names(Auto)
summary(Auto)
attach(Auto)
summary(mpg)
```

## Ilustración de la aproximación del conjunto de validación

Comenzamos ilustrando la aproximación basada en el conjunto de validación.
Fijamos la semilla para poder reproducir resultados 
y partimos la muestra (sus indices en dos mitades). Ajustamos
un modelo lineal de mpg sobre horsepower sobre el subconjunto de entrenamiento.
```{r ,eval=FALSE}
set.seed(1)
train=sample(392,196)
train
lm.fit=lm(mpg~horsepower,data=Auto,subset=train)
lm.fit
summary(lm.fit)
```
Usamos la función predict para predecir en el conjunto de validación 
(designado mediante -train) y sacamos el error cuadrático medio de test. Repetimos
con un modelo cuadrático y uno cúbico. Los resultados sugieren que hay una mejora
del modelo lineal al cuadrático, pero no hay mucha diferencia al pasar al
modelo cúbico.
```{r ,eval=FALSE}
mean((mpg-predict(lm.fit,Auto))[-train]^2)
lm.fit2=lm(mpg~poly(horsepower,2),data=Auto,subset=train)
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
lm.fit3=lm(mpg~poly(horsepower,3),data=Auto,subset=train)
mean((mpg-predict(lm.fit3,Auto))[-train]^2)
```
Repetimos el proceso con otro conjunto de validación. Los resultados serán 
algo diferentes pero vienen a dar la misma información.
```{r ,eval=FALSE}
set.seed(2)
train=sample(392,196)
lm.fit=lm(mpg~horsepower,subset=train)
mean((mpg-predict(lm.fit,Auto))[-train]^2)
lm.fit2=lm(mpg~poly(horsepower,2),data=Auto,subset=train)
mean((mpg-predict(lm.fit2,Auto))[-train]^2)
lm.fit3=lm(mpg~poly(horsepower,3),data=Auto,subset=train)
mean((mpg-predict(lm.fit3,Auto))[-train]^2)
```
Sugieren de nuevo, que el modelo cuadrático es mejor que el lineal pero no
se gana mucho con el cúbico respecto del cuadrático.

# Validación cruzada Leave-One-Out 

Ilustramos este concepto que lo proporciona de forma automática cv.glm y glm.
Observemos primero que si no especificamos la familia del glm hacemos 
un modelo lineal. Fijaos que coinciden. Hacemos antes help(glm) para entender
esta librería.
```{r ,eval=FALSE}
help(glm)
glm.fit=glm(mpg~horsepower,data=Auto)
coef(glm.fit)
lm.fit=lm(mpg~horsepower,data=Auto)
coef(lm.fit)
```
cv.glm es parte de la librería boot. Como otras veces cargáis y
hacéis luego help(cv.glm). Como n ponemos K en el call a cv.glm 
se interpreta como leave-one-out. cv.err$delta[1] contiene el estadistico 
LOOCV.
```{r ,eval=FALSE}
library(boot)
glm.fit=glm(mpg~horsepower,data=Auto)
help(cv.glm)
cv.err=cv.glm(Auto,glm.fit)
cv.err$delta[1]
```
Ahora hacemos un ejercicio similar con polinomios de grado creciente (de 1 
a 5). Inicializamos a 0 el vector de resultados y repetimos. De nuevo
observamos que ganamos
pasando del modelo lineal al cuadrático pero a partir de ahí no se
gana mucho más. Tarda un ratito....
```{r ,eval=FALSE}
cv.error=rep(0,5)
cv.error
for (i in 1:5){
 glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
 cv.error[i]=cv.glm(Auto,glm.fit)$delta[1]
 }
cv.error
plot(cv.error)
```

# Validación cruzada k-Fold 

Podemos usar también cv.glm para hacer VC k-fold (de k pliegues). Cogemos
aquí k=10, una selección habitual (también es habitual usar k=5). Fijamos de nuevo la semilla.
Inicializamos el vector donde guardamos resultados y hacemos la validación.

```{r ,eval=FALSE}
set.seed(17)
cv.error.6=rep(0,6)
cv.error.6
for (i in 1:6){
 glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
 cv.error.6[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
 }
cv.error.6
plot(cv.error.6)
```
Las conclusiones son similares a las anteriores.



